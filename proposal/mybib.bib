@phdthesis{soderblom1970distribution,
  title={The distribution and ages of regional lithologies in the lunar maria},
  author={Soderblom, Laurence Albert},
  year={1970},
  school={California Institute of Technology}
}

@article{uijlings2013selective,
  title={Selective search for object recognition},
  author={Uijlings, Jasper RR and Van De Sande, Koen EA and Gevers, Theo and Smeulders, Arnold WM},
  journal={International journal of computer vision},
  volume={104},
  number={2},
  pages={154--171},
  year={2013},
  publisher={Springer}
}

@inproceedings{felzenszwalb2008discriminatively,
  title={A discriminatively trained, multiscale, deformable part model},
  author={Felzenszwalb, Pedro and McAllester, David and Ramanan, Deva},
  booktitle={2008 IEEE conference on computer vision and pattern recognition},
  pages={1--8},
  year={2008},
  organization={IEEE}
}

@article{viola2001rapid,
  title={Rapid object detection using a boosted cascade of simple features},
  author={Viola, Paul and Jones, Michael and others},
  journal={CVPR (1)},
  volume={1},
  number={511-518},
  pages={3},
  year={2001}
}

@inproceedings{dalal2005histograms,
  title={Histograms of oriented gradients for human detection},
  author={Dalal, Navneet and Triggs, Bill},
  year={2005}
}

@article{dino2020,
  title={Landing site characterization for the PTS lunar mission to the Apollo 17 area},
  author={Dino Polegubic},
  journal={Master thesis at the Technical University of Berlin},
  year={2020},
  publisher={Technical University of Berlin}
}

@article{Snuverink2017,
  title={Deep Learning for Pixelwise Classification of Hyperspectral Images},
  author={I.A.F. Snuverink},
  journal={Master of Science Thesis},
  year={2017},
  publisher={Delft University of Technology, Netherlands}
}

@article{delatte2019segmentation,
  title={Segmentation Convolutional Neural Networks for Automatic Crater Detection on Mars},
  author={DeLatte, Danielle M and Crites, Sarah T and Guttenberg, Nicholas and Tasker, Elizabeth J and Yairi, Takehisa},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={8},
  pages={2944--2957},
  year={2019},
  publisher={IEEE}
}

@article{duda1972use,
  title={Use of the Hough transformation to detect lines and curves in pictures},
  author={Duda, Richard O and Hart, Peter E},
  journal={Communications of the ACM},
  volume={15},
  number={1},
  pages={11--15},
  year={1972},
  publisher={ACM New York, NY, USA}
}

@book{reiss1993recognizing,
  title={Recognizing planar objects using invariant image features},
  author={Reiss, Thomas H},
  volume={17},
  year={1993},
  publisher={Springer}
}

@article{finkelsteinautomatic,
  title={Automatic Lunar Crater Detection from Optical Images and Elevation Maps},
  author={Finkelstein, Mara and Baby, Susanna Maria and Kitano, Hugo}
}

@article{dvornik2019importance,
  title={On the importance of visual context for data augmentation in scene understanding},
  author={Dvornik, Nikita and Mairal, Julien and Schmid, Cordelia},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2019},
  publisher={IEEE}
}

@inproceedings{dwibedi2017cut,
  title={Cut, paste and learn: Surprisingly easy synthesis for instance detection},
  author={Dwibedi, Debidatta and Misra, Ishan and Hebert, Martial},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1301--1310},
  year={2017}
}

@article{ali2019automated,
  title={Automated crater shape retrieval using weakly-supervised deep learning},
  author={Ali-Dib, Mohamad and Menou, Kristen and Zhu, Chenchong and Hammond, Noah and Jackson, Alan P},
  journal={arXiv preprint arXiv:1906.08826},
  year={2019}
}

@article{leroy2001crater,
  title={Crater detection for autonomous landing on asteroids},
  author={Leroy, Bertrand and Medioni, G{\'e}rard and Johnson, E and Matthies, Larry},
  journal={Image and Vision Computing},
  volume={19},
  number={11},
  pages={787--792},
  year={2001},
  publisher={Elsevier}
}

@article{sezgin2004survey,
  title={Survey over image thresholding techniques and quantitative performance evaluation},
  author={Sezgin, Mehmet and Sankur, B{\"u}lent},
  journal={Journal of Electronic imaging},
  volume={13},
  number={1},
  pages={146--166},
  year={2004},
  publisher={International Society for Optics and Photonics}
}

@article{li1993minimum,
  title={Minimum cross entropy thresholding},
  author={Li, Chun Hung and Lee, CK},
  journal={Pattern recognition},
  volume={26},
  number={4},
  pages={617--625},
  year={1993},
  publisher={Elsevier}
}

@article{ridler1978picture,
  title={Picture thresholding using an iterative selection method},
  author={Ridler, TW and Calvard, S and others},
  journal={IEEE transactions on Systems, Man and Cybernetics},
  volume={8},
  number={8},
  pages={630--632},
  year={1978}
}

@article{yen1995new,
  title={A new criterion for automatic multilevel thresholding},
  author={Yen, Jui-Cheng and Chang, Fu-Juay and Chang, Shyang},
  journal={IEEE Transactions on Image Processing},
  volume={4},
  number={3},
  pages={370--378},
  year={1995},
  publisher={IEEE}
}

@article{greeley1970precision,
  title={Precision size-frequency distributions of craters for 12 selected areas of the lunar surface},
  author={Greeley et al., Gault, Donald E},
  journal={The Moon},
  volume={2},
  number={1},
  pages={10--77},
  year={1970},
  publisher={Springer}
}

@misc{ivanov2015probabilistic,
  title={Probabilistic surface characterization for safe landing hazard detection and avoidance (HDA)},
  author={Ivanov, Tonislav I and Huertas, Andres and Johnson, Andrew E},
  year={2015},
  month=sep # "~22",
  publisher={Google Patents},
  note={US Patent 9,141,113}
}

@article{melosh1988rocky,
  title={The rocky road to panspermia},
  author={Melosh, HJ},
  journal={Nature},
  volume={332},
  number={6166},
  pages={687},
  year={1988},
  publisher={Nature Publishing Group}
}

@article{brunelli1993face,
  title={Face recognition: Features versus templates},
  author={Brunelli, Roberto and Poggio, Tomaso},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={15},
  number={10},
  pages={1042--1052},
  year={1993},
  publisher={IEEE}
}

@article{burl2001automated,
  title={Automated detection of craters and other geological features},
  author={Burl, Michael C and Stough, Tim and Colwell, W and Bierhaus, EB and Merline, WJ and Chapman, C},
  year={2001}
}

@article{cohen2016crater,
  title={Crater detection via convolutional neural networks},
  author={Cohen, Joseph Paul and Lo, Henry Z and Lu, Tingting and Ding, Wei},
  journal={arXiv preprint arXiv:1601.00978},
  year={2016}
}

@article{ding2011subkilometer,
  title={Subkilometer crater discovery with boosting and transfer learning},
  author={Ding, Wei and Stepinski, Tomasz F and Mu, Yang and Bandeira, Lourenco and Ricardo, Ricardo and Wu, Youxi and Lu, Zhenyu and Cao, Tianyu and Wu, Xindong},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={2},
  number={4},
  pages={39},
  year={2011},
  publisher={ACM}
}

@article{thoma2016survey,
  title={A survey of semantic segmentation},
  author={Thoma, Martin},
  journal={arXiv preprint arXiv:1602.06541},
  year={2016}
}

@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

@incollection{stepinski2012detecting,
  title={Detecting impact craters in planetary images using machine learning},
  author={Stepinski, TF and Ding, Wei and Vilalta, R},
  booktitle={Intelligent data analysis for real-life applications: theory and practice},
  pages={146--159},
  year={2012},
  publisher={IGI Global}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}

@article{silburt2019lunar,
  title={Lunar crater identification via deep learning},
  author={Silburt, Ari and Ali-Dib, Mohamad and Zhu, Chenchong and Jackson, Alan and Valencia, Diana and Kissin, Yevgeni and Tamayo, Daniel and Menou, Kristen},
  journal={Icarus},
  volume={317},
  pages={27--38},
  year={2019},
  publisher={Elsevier}
}

@article{li2018h,
  title={H-DenseUNet: hybrid densely connected UNet for liver and tumor segmentation from CT volumes},
  author={Li, Xiaomeng and Chen, Hao and Qi, Xiaojuan and Dou, Qi and Fu, Chi-Wing and Heng, Pheng-Ann},
  journal={IEEE transactions on medical imaging},
  volume={37},
  number={12},
  pages={2663--2674},
  year={2018},
  publisher={IEEE}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{neukum1983meteoritenbombardement,
  title={Meteoritenbombardement und Datierung planetarer Oberfl{\"a}chen, Habilitation dissertation for faculty membership},
  author={Neukum, G},
  journal={Ludwig-Maximilians-University, Munich},
  pages={186},
  year={1983}
}

@article{hiesinger2000ages,
  title={Ages of mare basalts on the lunar nearside},
  author={Hiesinger, Harald and Jaumann, Ralf and Neukum, Gerhard and Head III, James W},
  journal={Journal of Geophysical Research: Planets},
  volume={105},
  number={E12},
  pages={29239--29275},
  year={2000},
  publisher={Wiley Online Library}
}

@article{neukum1994crater,
  title={Crater size distributions and impact probabilities on Earth from lunar, terrestrial-planet, and asteroid cratering data},
  author={Neukum, G and Ivanov, BA},
  journal={Hazards due to Comets and Asteroids},
  volume={1},
  pages={359--416},
  year={1994}
}

@incollection{stoffler2001stratigraphy,
  title={Stratigraphy and isotope ages of lunar geologic units: Chronological standard for the inner solar system},
  author={St{\"o}ffler, Dieter and Ryder, G},
  booktitle={Chronology and evolution of Mars},
  pages={9--54},
  year={2001},
  publisher={Springer}
}

@incollection{stoffler2001stratigraphy,
  title={Stratigraphy and isotope ages of lunar geologic units: Chronological standard for the inner solar system},
  author={St{\"o}ffler, Dieter and Ryder, G},
  booktitle={Chronology and evolution of Mars},
  pages={9--54},
  year={2001},
  publisher={Springer}
}

@article{hiesinger2000ages,
  title={Ages of mare basalts on the lunar nearside},
  author={Hiesinger, Harald and Jaumann, Ralf and Neukum, Gerhard and Head III, James W},
  journal={Journal of Geophysical Research: Planets},
  volume={105},
  number={E12},
  pages={29239--29275},
  year={2000},
  publisher={Wiley Online Library}
}

@article{soderblom1972technique,
  title={Technique for rapid determination of relative ages of lunar areas from orbital photography},
  author={Soderblom, Laurence A and Lebofsky, Larry A},
  journal={Journal of Geophysical Research},
  volume={77},
  number={2},
  pages={279--296},
  year={1972},
  publisher={Wiley Online Library}
}

@article{hartmann1981chronology,
  title={Chronology of planetary volcanism by comparative studies of planetary cratering},
  author={Hartmann, William K},
  journal={Basaltic Volcanism on the Terrestrial Planets.},
  pages={1049--1127},
  year={1981},
  publisher={Pergamon}
}


@misc{opik1965mariner,
  title={Mariner IV and craters on Mars},
  author={Opik, EJ},
  year={1965}
}

@article{williams2018dating,
  title={Dating very young planetary surfaces from crater statistics: A review of issues and challenges},
  author={Williams, Jean-Pierre and van der Bogert, Carolyn H and Pathare, Asmin V and Michael, Gregory G and Kirchoff, Michelle R and Hiesinger, Harald},
  journal={Meteoritics \& Planetary Science},
  volume={53},
  number={4},
  pages={554--582},
  year={2018},
  publisher={Wiley Online Library}
}

@article{ivanov2002comparison,
  title={The comparison of size-frequency distributions of impact craters and asteroids and the planetary cratering rate},
  author={Ivanov, BA},
  journal={Asteroids III},
  volume={1},
  pages={89--101},
  year={2002},
  publisher={this volume. Univ. of Arizona, Tucson}
}


@inproceedings{neukum1975cratering,
  title={Cratering in the Earth-Moon system-Consequences for age determination by crater counting},
  author={Neukum, Gerhard and K{\"o}nig, B and Fechtig, H and Storzer, D},
  booktitle={Lunar and Planetary Science Conference Proceedings},
  volume={6},
  pages={2597--2620},
  year={1975}
}

@article{2016face,
  title={Face recognition across time lapse using convolutional neural networks},
  author={El Khiyari, Hachim and Wechsler, Harry},
  journal={Journal of Information Security},
  volume={7},
  number={03},
  pages={141},
  year={2016},
  publisher={Scientific Research Publishing}
}

@InProceedings{Redmon_2016_CVPR,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
title = {You Only Look Once: Unified, Real-Time Object Detection},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{martins2009crater,
  title={Crater detection by a boosting approach},
  author={Martins, Ricardo and Pina, Pedro and Marques, Jorge S and Silveira, Margarida},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={6},
  number={1},
  pages={127--131},
  year={2009},
  publisher={IEEE}
}
@article{koeberl1994african,
  title={African meteorite impact craters: Characteristics and geological importance},
  author={Koeberl, Christian},
  journal={Journal of African Earth Sciences},
  volume={18},
  number={4},
  pages={263--295},
  year={1994},
  publisher={Elsevier}
}
@article{girshick_rich_2013,
	title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
	url = {http://arxiv.org/abs/1311.2524},
	abstract = {Object detection performance, as measured on the canonical {PASCAL} {VOC} dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision ({mAP}) by more than 30\% relative to the previous best result on {VOC} 2012---achieving a {mAP} of 53.3\%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks ({CNNs}) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with {CNNs}, we call our method R-{CNN}: Regions with {CNN} features. We also compare R-{CNN} to {OverFeat}, a recently proposed sliding-window detector based on a similar {CNN} architecture. We find that R-{CNN} outperforms {OverFeat} by a large margin on the 200-class {ILSVRC}2013 detection dataset. Source code for the complete system is available at http://www.cs.berkeley.edu/{\textasciitilde}rbg/rcnn.},
	journaltitle = {{arXiv}:1311.2524 [cs]},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	urldate = {2018-03-27},
	date = {2013-11-11},
	eprinttype = {arxiv},
	eprint = {1311.2524},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1311.2524 PDF:/Users/wtahir/Zotero/storage/GTLDGBHR/Girshick et al. - 2013 - Rich feature hierarchies for accurate object detec.pdf:application/pdf;arXiv.org Snapshot:/Users/wtahir/Zotero/storage/GY4FNAHE/1311.html:text/html}
}

@inproceedings{szegedy_going_2015,
	title = {Going deeper with convolutions},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298594/},
	doi = {10.1109/CVPR.2015.7298594},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classiﬁcation and detection in the {ImageNet} Large-Scale Visual Recognition Challenge 2014 ({ILSVRC}14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for {ILSVRC}14 is called {GoogLeNet}, a 22 layers deep network, the quality of which is assessed in the context of classiﬁcation and detection.},
	pages = {1--9},
	publisher = {{IEEE}},
	author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	urldate = {2018-04-09},
	date = {2015-06},
	langid = {english},
	file = {Szegedy et al. - 2015 - Going deeper with convolutions.pdf:/Users/wtahir/Zotero/storage/ZH2A4D2P/Szegedy et al. - 2015 - Going deeper with convolutions.pdf:application/pdf}
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2018-04-09},
	date = {2015-05},
	langid = {english},
	file = {CNN based edge detection.pdf:/Users/wtahir/Zotero/storage/4F8WS92L/CNN based edge detection.pdf:application/pdf;LeCun et al. - 2015 - Deep learning.pdf:/Users/wtahir/Zotero/storage/243SXBTA/LeCun et al. - 2015 - Deep learning.pdf:application/pdf}
}

@inproceedings{chen_vehicle_2013,
	title = {Vehicle Detection in Satellite Images by Parallel Deep Convolutional Neural Networks},
	isbn = {978-1-4799-2190-4},
	url = {http://ieeexplore.ieee.org/document/6778306/},
	doi = {10.1109/ACPR.2013.33},
	abstract = {Deep convolutional Neural Networks ({DNN}) is the state-of-the-art machine learning method. It has been used in many recognition tasks including handwritten digits, Chinese words and trafﬁc signs, etc. However, training and test {DNN} are time-consuming tasks. In practical vehicle detection application, both speed and accuracy are required. So increasing the speeds of {DNN} while keeping its high accuracy has signiﬁcant meaning for many recognition and detection applications. We introduce parallel branches into the {DNN}. The maps of the layers of {DNN} are divided into several parallel branches, each branch has the same number of maps. There are not direct connections between different branches. Our parallel {DNN} ({PNN}) keeps the same structure and dimensions of the {DNN}, reducing the total number of connections between maps. The more number of branches we divide, the more swift the speed of the {PNN} is, the conventional {DNN} becomes a special form of {PNN} which has only one branch. Experiments on large vehicle database showed that the detection accuracy of {PNN} dropped slightly with the speed increasing. Even the fastest {PNN} (10 times faster than {DNN}), whose branch has only two maps, fully outperformed the traditional methods based on features (such as {HOG}, {LBP}). In fact, {PNN} provides a good solution way for compromising the speed and accuracy requirements in many applications.},
	pages = {181--185},
	publisher = {{IEEE}},
	author = {Chen, Xueyun and Xiang, Shiming and Liu, Cheng-Lin and Pan, Chun-Hong},
	urldate = {2018-04-09},
	date = {2013-11},
	langid = {english},
	file = {Chen et al. - 2013 - Vehicle Detection in Satellite Images by Parallel .pdf:/Users/wtahir/Zotero/storage/7GRF7YWX/Chen et al. - 2013 - Vehicle Detection in Satellite Images by Parallel .pdf:application/pdf}
}

@article{zhong_satcnn:_2017,
	title = {{SatCNN}: satellite image dataset classification using agile convolutional neural networks},
	volume = {8},
	issn = {2150-704X, 2150-7058},
	url = {https://www.tandfonline.com/doi/full/10.1080/2150704X.2016.1235299},
	doi = {10.1080/2150704X.2016.1235299},
	shorttitle = {{SatCNN}},
	abstract = {With the launch of various remote-sensing satellites, more and more high-spatial resolution remote-sensing ({HSR}-{RS}) images are becoming available. Scene classiﬁcation of such a huge volume of {HSR}-{RS} images is a big challenge for the eﬃciency of the feature learning and model training. The deep convolutional neural network ({CNN}), a typical deep learning model, is an eﬃcient end-toend deep hierarchical feature learning model that can capture the intrinsic features of input {HSR}-{RS} images. However, most published {CNN} architectures are borrowed from natural scene classiﬁcation with thousands of training samples, and they are not designed for {HSR}-{RS} images. In this paper, we propose an agile {CNN} architecture, named as {SatCNN}, for {HSR}-{RS} image scene classiﬁcation. Based on recent improvements to modern {CNN} architectures, we use more eﬃcient convolutional layers with smaller kernels to build an eﬀective {CNN} architecture. Experiments on {SAT} data sets conﬁrmed that {SatCNN} can quickly and eﬀectively learn robust features to handle the intra-class diversity even with small convolutional kernels, and the deeper convolutional layers allow spontaneous modelling of the relative spatial relationships. With the help of fast graphics processing unit acceleration, {SatCNN} can be trained within about 40 min, achieving overall accuracies of 99.65\% and 99.54\%, which is the state-ofthe-art for {SAT} data sets.},
	pages = {136--145},
	number = {2},
	journaltitle = {Remote Sensing Letters},
	author = {Zhong, Yanfei and Fei, Feng and Liu, Yanfei and Zhao, Bei and Jiao, Hongzan and Zhang, Liangpei},
	urldate = {2018-04-09},
	date = {2017-02},
	langid = {english},
	file = {Zhong et al. - 2017 - SatCNN satellite image dataset classification usi.pdf:/Users/wtahir/Zotero/storage/TU2SLCEY/Zhong et al. - 2017 - SatCNN satellite image dataset classification usi.pdf:application/pdf}
}

@article{martins2009crater,
  title={Crater detection by a boosting approach},
  author={Martins, Ricardo and Pina, Pedro and Marques, Jorge S and Silveira, Margarida},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={6},
  number={1},
  pages={127--131},
  year={2009},
  publisher={IEEE}
}

@article{robinson2010lunar,
  title={Lunar reconnaissance orbiter camera (LROC) instrument overview},
  author={Robinson, MS and Brylow, SM and Tschimmel, M and Humm, D and Lawrence, SJ and Thomas, PC and Denevi, BW and Bowman-Cisneros, E and Zerr, J and Ravine, MA and others},
  journal={Space science reviews},
  volume={150},
  number={1-4},
  pages={81--124},
  year={2010},
  publisher={Springer}
}

@article{zhang_s-cnn-based_2016,
	title = {S-{CNN}-{BASED} {SHIP} {DETECTION} {FROM} {HIGH}-{RESOLUTION} {REMOTE} {SENSING} {IMAGES}},
	volume = {{XLI}-B7},
	issn = {2194-9034},
	url = {http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B7/423/2016/isprs-archives-XLI-B7-423-2016.pdf},
	doi = {10.5194/isprsarchives-XLI-B7-423-2016},
	abstract = {Reliable ship detection plays an important role in both military and civil ﬁelds. However, it makes the task difﬁcult with high-resolution remote sensing images with complex background and various types of ships with different poses, shapes and scales. Related works mostly used gray and shape features to detect ships, which obtain results with poor robustness and efﬁciency. To detect ships more automatically and robustly, we propose a novel ship detection method based on the convolutional neural networks ({CNNs}), called {SCNN}, fed with speciﬁcally designed proposals extracted from the ship model combined with an improved saliency detection method. Firstly we creatively propose two ship models, the “V” ship head model and the “{\textbar}{\textbar}” ship body one, to localize the ship proposals from the line segments extracted from a test image. Next, for offshore ships with relatively small sizes, which cannot be efﬁciently picked out by the ship models due to the lack of reliable line segments, we propose an improved saliency detection method to ﬁnd these proposals. Therefore, these two kinds of ship proposals are fed to the trained {CNN} for robust and efﬁcient detection. Experimental results on a large amount of representative remote sensing images with different kinds of ships with varied poses, shapes and scales demonstrate the efﬁciency and robustness of our proposed S-{CNN}-Based ship detector.},
	pages = {423--430},
	journaltitle = {{ISPRS} - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Zhang, Ruiqian and Yao, Jian and Zhang, Kao and Feng, Chen and Zhang, Jiadong},
	urldate = {2018-04-09},
	date = {2016-06-21},
	langid = {english},
	file = {Zhang et al. - 2016 - S-CNN-BASED SHIP DETECTION FROM HIGH-RESOLUTION RE.pdf:/Users/wtahir/Zotero/storage/IEDTTJ3I/Zhang et al. - 2016 - S-CNN-BASED SHIP DETECTION FROM HIGH-RESOLUTION RE.pdf:application/pdf}
}

@inproceedings{ishii_surface_2015,
	title = {Surface object recognition with {CNN} and {SVM} in Landsat 8 images},
	isbn = {978-4-901122-14-6},
	url = {http://ieeexplore.ieee.org/document/7153200/},
	doi = {10.1109/MVA.2015.7153200},
	abstract = {There is a series of earth observation satellites called Landsat, which send a very large amount of image data every day such that it is hard to analyze manually. Thus an eﬀective application of machine learning techniques to automatically analyze such data is called for. In surface object recognition, which is one of the important applications of such data, the distribution of a speciﬁc object on the surface is surveyed. In this paper, we propose and compare two methods for surface object recognition, one using the convolutional neural network ({CNN}) and the other support vector machine ({SVM}). In our experiments, {CNN} showed higher performance than {SVM}. In addition, we observed that the number of negative samples have a inﬂuence on the performance, and it is necessary to select the number of them for practical use.},
	pages = {341--344},
	publisher = {{IEEE}},
	author = {Ishii, Tomohiro and Nakamura, Ryosuke and Nakada, Hidemoto and Mochizuki, Yoshihiko and Ishikawa, Hiroshi},
	urldate = {2018-04-09},
	date = {2015-05},
	langid = {english},
	file = {Ishii et al. - 2015 - Surface object recognition with CNN and SVM in Lan.pdf:/Users/wtahir/Zotero/storage/SEVX5QPX/Ishii et al. - 2015 - Surface object recognition with CNN and SVM in Lan.pdf:application/pdf}
}

@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@inproceedings{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in neural information processing systems},
  pages={91--99},
  year={2015}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{stepinski2009machine,
  title={Machine cataloging of impact craters on Mars},
  author={Stepinski, Tomasz F and Mendenhall, Michael P and Bue, Brian D},
  journal={icarus},
  volume={203},
  number={1},
  pages={77--87},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{vinogradova2002training,
  title={Training of a crater detection algorithm for Mars crater imagery},
  author={Vinogradova, Tatiana and Burl, Michael and Mjolsness, Eric},
  booktitle={Proceedings, IEEE Aerospace Conference},
  volume={7},
  pages={7--7},
  year={2002},
  organization={IEEE}
}

@inproceedings{wetzler2005learning,
  title={Learning to detect small impact craters},
  author={Wetzler, Philipp Georg and Honda, Rie and Enke, B and Merline, William J and Chapman, Clark R and Burl, Michael C},
  booktitle={2005 Seventh IEEE Workshops on Applications of Computer Vision (WACV/MOTION'05)-Volume 1},
  volume={1},
  pages={178--184},
  year={2005},
  organization={IEEE}
}

@article{honda2000crater,
  title={Crater extraction and classification system for lunar images},
  author={Honda, Rie and Azuma, Ryushi},
  journal={Mem. Fac. Sci. Kochi Univ.(Inform. Sci.)},
  volume={21},
  pages={13--22},
  year={2000}
}

@inproceedings{emami2015automatic,
  title={Automatic crater detection using convex grouping and convolutional neural networks},
  author={Emami, Ebrahim and Bebis, George and Nefian, Ara and Fong, Terry},
  booktitle={International Symposium on Visual Computing},
  pages={213--224},
  year={2015},
  organization={Springer}
}

@article{palafox2017automated,
  title={Automated detection of geological landforms on Mars using Convolutional Neural Networks},
  author={Palafox, Leon F and Hamilton, Christopher W and Scheidt, Stephen P and Alvarez, Alexander M},
  journal={Computers \& geosciences},
  volume={101},
  pages={48--56},
  year={2017},
  publisher={Elsevier}
}

@article{wang2018crateridnet,
  title={CraterIDNet: an end-to-end fully convolutional neural network for crater detection and identification in remotely sensed planetary images},
  author={Wang, Hao and Jiang, Jie and Zhang, Guangjun},
  journal={Remote Sensing},
  volume={10},
  number={7},
  pages={1067},
  year={2018},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{bandeira2010automatic,
  title={Automatic detection of sub-km craters using shape and texture information},
  author={Bandeira, L and Ding, W and Stepinski, TF},
  booktitle={Lunar and Planetary Science Conference},
  volume={41},
  pages={1144},
  year={2010}
}

@article{ding2011subkilometer,
  title={Subkilometer crater discovery with boosting and transfer learning},
  author={Ding, Wei and Stepinski, Tomasz F and Mu, Yang and Bandeira, Lourenco and Ricardo, Ricardo and Wu, Youxi and Lu, Zhenyu and Cao, Tianyu and Wu, Xindong},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={2},
  number={4},
  pages={39},
  year={2011},
  publisher={ACM}
}

@book{burger2009principles,
  title={Principles of digital image processing},
  author={Burger, Wilhelm and Burge, Mark James and Burge, Mark James and Burge, Mark James},
  volume={54},
  year={2009},
  publisher={Springer}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{badrinarayanan2017segnet,
  title={Segnet: A deep convolutional encoder-decoder architecture for image segmentation},
  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={12},
  pages={2481--2495},
  year={2017},
  publisher={IEEE}
}

@article{urbach2009automatic,
  title={Automatic detection of sub-km craters in high resolution planetary images},
  author={Urbach, Erik R and Stepinski, Tomasz F},
  journal={Planetary and Space Science},
  volume={57},
  number={7},
  pages={880--887},
  year={2009},
  publisher={Elsevier}
}

@article{meng2009method,
  title={Method of passive image based crater autonomous detection},
  author={Meng, Ding and Yunfeng, Cao and Qingxian, Wu},
  journal={Chinese Journal of Aeronautics},
  volume={22},
  number={3},
  pages={301--306},
  year={2009},
  publisher={Elsevier}
}

@article{salamuniccar2010method,
  title={Method for crater detection from martian digital topography data using gradient value/orientation, morphometry, vote analysis, slip tuning, and calibration},
  author={Salamuniccar, Goran and Loncaric, Sven},
  journal={IEEE transactions on Geoscience and Remote Sensing},
  volume={48},
  number={5},
  pages={2317--2329},
  year={2010},
  publisher={IEEE}
}

@article{honda2000crater,
  title={Crater extraction and classification system for lunar images},
  author={Honda, Rie and Azuma, Ryushi},
  journal={Mem. Fac. Sci. Kochi Univ.(Inform. Sci.)},
  volume={21},
  pages={13--22},
  year={2000}
}

@inproceedings{xie_aggregated_2017,
	title = {Aggregated residual transformations for deep neural networks},
	isbn = {1-5386-0457-4},
	eventtitle = {Computer Vision and Pattern Recognition ({CVPR}), 2017 {IEEE} Conference on},
	pages = {5987--5995},
	publisher = {{IEEE}},
	author = {Xie, Saining and Girshick, Ross and Dollár, Piotr and Tu, Zhuowen and He, Kaiming},
	date = {2017}
}

@article{he_mask_2017,
	title = {Mask R-{CNN}},
	url = {http://arxiv.org/abs/1703.06870},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-{CNN}, extends Faster R-{CNN} by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-{CNN} is simple to train and adds only a small overhead to Faster R-{CNN}, running at 5 fps. Moreover, Mask R-{CNN} is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the {COCO} suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-{CNN} outperforms all existing, single-model entries on every task, including the {COCO} 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
	journaltitle = {{arXiv}:1703.06870 [cs]},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	urldate = {2018-05-13},
	date = {2017-03-20},
	eprinttype = {arxiv},
	eprint = {1703.06870},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1703.06870 PDF:/Users/wtahir/Zotero/storage/X5K5UUZ7/He et al. - 2017 - Mask R-CNN.pdf:application/pdf;arXiv.org Snapshot:/Users/wtahir/Zotero/storage/3N3ZU6WI/1703.html:text/html}
}

@article{sawabe_2006,
	title = {Automated detection and classification of lunar craters using multiple approaches},
	volume = {37},
	issn = {02731177},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0273117705010392},
	doi = {10.1016/j.asr.2005.08.022},
	abstract = {Many missions such as Clementine and {SELENE} ({SELenological} and Engineering Explorer) take lunar images for examination. A large volume of imagery data has already been archived and much more is on the way. Extracting the necessary information from the already large and ever growing volume of data is the crucial problem that needs to be overcome.},
	pages = {21--27},
	number = {1},
	journaltitle = {Advances in Space Research},
	author = {Sawabe, Y. and Matsunaga, T. and Rokugawa, S.},
	urldate = {2018-05-14},
	year = {2006},
	langid = {english},
	file = {Sawabe et al. - 2006 - Automated detection and classification of lunar cr.pdf:/Users/wtahir/Zotero/storage/ZMHMWC8I/Sawabe et al. - 2006 - Automated detection and classification of lunar cr.pdf:application/pdf}
}

@article{chartock_extraction_????,
	title = {Extraction of Building Footprints from Satellite Imagery},
	abstract = {We use a Fully Convolutional Neural Network to extract bounding polygons for building footprints. Our network takes in 11-band satellite image data and produces signed distance labels, denoting which pixels are inside and outside of building footprints. Finally, we post-process the data to produce bounding polygons. When a similar dataset was ﬁrst released as part of the ﬁrst {SpaceNet} Challenge, the winning implementation produced an F1 score of 0.25 and used no deep learning; our approach outperforms this with an F1 score of 0.34.},
	pages = {8},
	author = {Chartock, Elliott and {LaRow}, Whitney and Singh, Vijay},
	langid = {english},
	file = {Chartock et al. - Extraction of Building Footprints from Satellite I.pdf:/Users/wtahir/Zotero/storage/IZRX525G/Chartock et al. - Extraction of Building Footprints from Satellite I.pdf:application/pdf}
}

@inproceedings{redmon_you_2016,
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780460/},
	doi = {10.1109/CVPR.2016.91},
	shorttitle = {You Only Look Once},
	abstract = {We present {YOLO}, a new approach to object detection. Prior work on object detection repurposes classiﬁers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.},
	pages = {779--788},
	publisher = {{IEEE}},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	urldate = {2018-05-14},
	date = {2016-06},
	langid = {english},
	file = {Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:/Users/wtahir/Zotero/storage/ECZHW82K/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf}
}
